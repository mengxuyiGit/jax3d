{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import os\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/xymeng/Repo/jax3d/jax3d/projects/mobilenerf/get_rays/rays_inverse_false.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tsfm_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/xymeng/Repo/jax3d/jax3d/projects/mobilenerf/get_rays/rays_inverse_false.json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(tsfm_path, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m jf:\n\u001b[1;32m      3\u001b[0m     data_inv_f \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(jf)\n\u001b[1;32m      5\u001b[0m tsfm_path_t \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/xymeng/Repo/jax3d/jax3d/projects/mobilenerf/get_rays/rays_inverse_true.json\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/xymeng/Repo/jax3d/jax3d/projects/mobilenerf/get_rays/rays_inverse_false.json'"
     ]
    }
   ],
   "source": [
    "tsfm_path = '/home/xymeng/Repo/jax3d/jax3d/projects/mobilenerf/get_rays/rays_inverse_false.json'\n",
    "with open(tsfm_path, 'r') as jf:\n",
    "    data_inv_f = json.load(jf)\n",
    "\n",
    "tsfm_path_t = '/home/xymeng/Repo/jax3d/jax3d/projects/mobilenerf/get_rays/rays_inverse_true.json'\n",
    "with open(tsfm_path_t, 'r') as jft:\n",
    "    data_inv_t = json.load(jft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inv_f = torch.tensor(data_inv_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512, 3, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_inv_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512, 3, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_inv_t = torch.tensor(data_inv_t)\n",
    "data_inv_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(data_inv_f[...,0,:]==data_inv_t[...,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(data_inv_f[...,1:,:]+data_inv_t[...,1:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 512, 2, 1]), torch.Size([512, 512, 2, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_inv_f[...,1:,:].shape, data_inv_t[...,1:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(128.5000),)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(data_inv_f[...,1:,:]).mean(), # data_inv_t[...,1:,:]\n",
    "# (data_inv_f[...,2:3,:]+data_inv_t[...,2:3,:]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00186171,  0.        , -0.50529986],\n",
       "        [ 0.        ,  0.00185973, -0.45087711],\n",
       "        [ 0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.00189753,  0.        , -0.4857685 ],\n",
       "        [ 0.        , -0.00189753,  0.4857685 ],\n",
       "        [ 0.        ,  0.        , -1.        ]]),\n",
       " array([[ 0.00189753,  0.        ,  0.4857685 ],\n",
       "        [ 0.        ,  0.00189753, -0.4857685 ],\n",
       "        [ 0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.00189753,  0.        , -0.4857685 ],\n",
       "        [ 0.        , -0.00189753,  0.4857685 ],\n",
       "        [ 0.        ,  0.        , -1.        ]]),\n",
       " array([[ 0.00186171,  0.        ,  0.50529986],\n",
       "        [ 0.        , -0.00185973,  0.45087711],\n",
       "        [ 0.        ,  0.        , -1.        ]]),\n",
       " array([[1.00000000e+00, 0.00000000e+00, 5.68434189e-14],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focal = 527\n",
    "width=height=512\n",
    "\n",
    "k_zju = np.array([[537.14068604,   0.        , 271.41711426],\n",
    "       [  0.        , 537.71148682, 242.44180298],\n",
    "       [  0.        ,   0.        ,   1.        ]])\n",
    "\n",
    "k = np.array([\n",
    "      [1./focal, 0, -.5 * width / focal],\n",
    "      [0, -1./focal, .5 * height / focal],\n",
    "      [0, 0, -1.],\n",
    "  ])\n",
    "kneg = np.array([\n",
    "      [1./focal, 0, .5 * width / focal],\n",
    "      [0, 1./focal, -.5 * height / focal],\n",
    "      [0, 0, 1.],\n",
    "  ])\n",
    "\n",
    "neg = np.array([\n",
    "      [1., 0, 0],\n",
    "      [0, -1., 0],\n",
    "      [0, 0, -1.],\n",
    "  ])\n",
    "\n",
    "np.linalg.inv(k_zju), k, kneg, np.matmul(kneg, neg), np.matmul(np.linalg.inv(k_zju), neg), np.matmul(k_zju, np.linalg.inv(k_zju))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## actual inv_K for ZJU\n",
    "DeviceArray([[ 0.00186171,  0.        ,  0.50529987],\n",
    "             [ 0.        , -0.00185973,  0.4508771 ],\n",
    "             [ 0.        ,  0.        , -1.        ]], dtype=float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.ones_like([3,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00186171,  0.        ,  0.50529982],\n",
       "       [ 0.        , -0.00185973,  0.4508771 ],\n",
       "       [ 0.        ,  0.        , -1.        ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_y_mul = np.array([\n",
    "      [1., 0, 0],\n",
    "      [0, -1., 0],\n",
    "      [0, 0, -1.],\n",
    "    ])\n",
    "K_zju = np.asarray([[537.1407,   0.0000, 271.4171],\n",
    "            [  0.0000, 537.7115, 242.4418],\n",
    "            [  0.0000,   0.0000,   1.0000]])\n",
    "inv_K = np.linalg.inv(K_zju)\n",
    "# st()\n",
    "np.matmul(inv_K, inverse_y_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(kt==kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  0.,  0.],\n",
       "         [ 0., -1.,  0.],\n",
       "         [ 0.,  0., -1.]], dtype=torch.float64),\n",
       " tensor([True]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz = torch.rand(10,10,3,1)\n",
    "xyz1 = xyz.clone()\n",
    "xyz1[...,1:,:] = xyz1[...,1:,:]*(-1)\n",
    "xyz2 = torch.matmul(torch.tensor(neg).float(), xyz.float())\n",
    "torch.tensor(neg), torch.unique(xyz2==xyz1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz3 = torch.matmul(torch.matmul(torch.tensor(k_zju).float(), torch.tensor(neg).float()), xyz.float())\n",
    "xyz4 = torch.matmul(torch.tensor(k_zju).float(), xyz2)\n",
    "torch.unique(xyz3==xyz4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "\n",
      "Pseudo-inverse of A:\n",
      "[[-1.3333334  -0.33333334  0.6666667 ]\n",
      " [ 1.0833334   0.33333334 -0.4166667 ]]\n",
      "\n",
      "A * A_pinv:\n",
      "[[ 0.8333334   0.33333334 -0.16666669]\n",
      " [ 0.3333335   0.33333337  0.33333325]\n",
      " [-0.16666698  0.33333325  0.8333335 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Define a matrix A\n",
    "A = jnp.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "# Compute the Moore-Penrose pseudo-inverse of A using NumPy\n",
    "A_pinv_np = np.linalg.pinv(A)\n",
    "\n",
    "# Convert the NumPy array to a JAX array\n",
    "A_pinv = jnp.array(A_pinv_np)\n",
    "\n",
    "# Multiply A by its pseudo-inverse (should give an identity-like matrix)\n",
    "result = jnp.matmul(A, A_pinv)\n",
    "\n",
    "print(\"A:\")\n",
    "print(A)\n",
    "print(\"\\nPseudo-inverse of A:\")\n",
    "print(A_pinv)\n",
    "print(\"\\nA * A_pinv:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "# Load data from the saved file\n",
    "param_fname = '/data/xymeng/Repo/humannerf/sample_motion_arrays.npz'\n",
    "with np.load(param_fname) as data:\n",
    "    jax_arrays = {key: jnp.array(value) for key, value in data.items()}\n",
    "# Create variables with the same name as the dictionary keys and assign the JAX arrays\n",
    "for key, value in jax_arrays.items():\n",
    "    exec(f\"{key} = value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rays = (jnp.array([512, 512, 4, 3]), jnp.array([512, 512, 4, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_motion_fields_forward_warp(\n",
    "        pts,\n",
    "        motion_scale_Rs,\n",
    "        motion_Ts,\n",
    "        motion_weights_vol,\n",
    "        cnl_bbox_min_xyz, cnl_bbox_scale_xyz,\n",
    "        output_list):\n",
    "    orig_shape = list(pts.shape)\n",
    "    pts = pts.reshape(-1, 3)  # [N_rays x N_samples, 3]\n",
    "\n",
    "    # remove BG channel\n",
    "    motion_weights = motion_weights_vol[:-1]\n",
    "\n",
    "    weights_list = []\n",
    "    for i in range(motion_weights.shape[0]):  # for each motion in total 24 motions\n",
    "\n",
    "        # forward_warp:\n",
    "        pos = pts\n",
    "        pos = (pos - cnl_bbox_min_xyz[None, :]) \\\n",
    "            * cnl_bbox_scale_xyz[None, :] - 1.0\n",
    "\n",
    "        # Use JAX's map_coordinates to replace torch's grid_sample\n",
    "        weights = map_coordinates(motion_weights[jnp.newaxis, i:i + 1, :, :, :], \n",
    "                                  pos[jnp.newaxis, jnp.newaxis, jnp.newaxis, :, :], \n",
    "                                  order=1)\n",
    "        weights = weights[0, 0, 0, 0, :, jnp.newaxis]  # (4194304, 1)\n",
    "        weights_list.append(weights)\n",
    "\n",
    "    backwarp_motion_weights = jnp.concatenate(weights_list, axis=-1)  # for each point, there is a weight for each motion\n",
    "    total_bases = backwarp_motion_weights.shape[-1]\n",
    "\n",
    "    backwarp_motion_weights_sum = jnp.sum(backwarp_motion_weights,\n",
    "                                          dim=-1, keepdims=True)\n",
    "    weighted_motion_fields = []\n",
    "    for i in range(total_bases):\n",
    "        # forward warp:\n",
    "        # using jax linalg: pos = linalg.matmul(linalg.inv(motion_scale_Rs[i, :, :]), (pts - motion_Ts[i, :]).T).T \n",
    "        ## FIXME: modified using numpuy, potential risk in gradient flow\n",
    "        pos = np.linalg.matmul(np.linalg.inv(motion_scale_Rs[i, :, :]), (pts - motion_Ts[i, :]).T).T\n",
    "        pos = jnp.array(pos)\n",
    "        weighted_pos = backwarp_motion_weights[:, i:i + 1] * pos\n",
    "        weighted_motion_fields.append(weighted_pos)\n",
    "    x_skel = jnp.sum(\n",
    "        jnp.stack(weighted_motion_fields, dim=0), dim=0\n",
    "    ) / backwarp_motion_weights_sum.clip(min=0.0001)\n",
    "    # the final pos is the weighted avg of all motions\n",
    "    fg_likelihood_mask = backwarp_motion_weights_sum\n",
    "\n",
    "    x_skel = x_skel.reshape(orig_shape[:2] + [3])\n",
    "    backwarp_motion_weights = \\\n",
    "        backwarp_motion_weights.reshape(orig_shape[:2] + [total_bases])\n",
    "    fg_likelihood_mask = fg_likelihood_mask.reshape(orig_shape[:2] + [1])\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    if 'x_skel' in output_list:  # [N_rays x N_samples, 3]\n",
    "        results['x_skel'] = x_skel\n",
    "    if 'fg_likelihood_mask' in output_list:  # [N_rays x N_samples, 1]\n",
    "        results['fg_likelihood_mask'] = fg_likelihood_mask\n",
    "\n",
    "    return results\n",
    "\n",
    "def sample_motion_fields_forward_warp_mobile_nerf(\n",
    "            rays,\n",
    "            motion_scale_Rs,\n",
    "            motion_Ts,\n",
    "            motion_weights_vol,\n",
    "            cnl_bbox_min_xyz,\n",
    "            cnl_bbox_scale_xyz,\n",
    "):\n",
    "  ## first reverse yz\n",
    "  rays = [ jnp.stack([_ray[..., 0], _ray[..., 2], _ray[..., 1]], axis=-1) for _ray in rays]\n",
    "  \n",
    "  ## begin warping\n",
    "  # reshape into (N, 3)\n",
    "  rays = [ x.reshape(1, -1, 3) for x in rays]\n",
    "  \n",
    "  # warping using weight vol\n",
    "  sample_motion_outs = []\n",
    "  for pts in rays:\n",
    "    mv_output = _sample_motion_fields_forward_warp(\n",
    "                      pts=pts,\n",
    "                      motion_scale_Rs=motion_scale_Rs[0], \n",
    "                      motion_Ts=motion_Ts[0], \n",
    "                      motion_weights_vol=motion_weights_vol,\n",
    "                      cnl_bbox_min_xyz=cnl_bbox_min_xyz, \n",
    "                      cnl_bbox_scale_xyz=cnl_bbox_scale_xyz,\n",
    "                      output_list=['x_skel', 'fg_likelihood_mask'])\n",
    "    pts_mask = mv_output['fg_likelihood_mask']\n",
    "    cnl_pts = mv_output['x_skel'].reshape(-1,3)\n",
    "    sample_motion_outs.append(cnl_pts)\n",
    "  \n",
    "  rays = sample_motion_outs\n",
    "\n",
    "  ## recover shape\n",
    "  rays = [ x.reshape(512,512, 4,3) for x in rays]\n",
    "  ## last reverse yz\n",
    "  rays = [ jnp.stack([_ray[..., 0], _ray[..., 2], _ray[..., 1]], axis=-1) for _ray in rays]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "coordinates must be a sequence of length input.ndim, but 1 != 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mndimage\u001b[39;00m \u001b[39mimport\u001b[39;00m map_coordinates\n\u001b[0;32m----> 2\u001b[0m warped_rays \u001b[39m=\u001b[39m sample_motion_fields_forward_warp_mobile_nerf(\n\u001b[1;32m      3\u001b[0m     rays\u001b[39m=\u001b[39;49mrays,\n\u001b[1;32m      4\u001b[0m     motion_scale_Rs\u001b[39m=\u001b[39;49mmotion_scale_Rs,\n\u001b[1;32m      5\u001b[0m     motion_Ts\u001b[39m=\u001b[39;49mmotion_Ts,\n\u001b[1;32m      6\u001b[0m     motion_weights_vol\u001b[39m=\u001b[39;49mmotion_weights_vol,\n\u001b[1;32m      7\u001b[0m     cnl_bbox_min_xyz\u001b[39m=\u001b[39;49mcnl_bbox_min_xyz,\n\u001b[1;32m      8\u001b[0m     cnl_bbox_scale_xyz\u001b[39m=\u001b[39;49mcnl_bbox_scale_xyz,\n\u001b[1;32m      9\u001b[0m   )\n",
      "Cell \u001b[0;32mIn[8], line 81\u001b[0m, in \u001b[0;36msample_motion_fields_forward_warp_mobile_nerf\u001b[0;34m(rays, motion_scale_Rs, motion_Ts, motion_weights_vol, cnl_bbox_min_xyz, cnl_bbox_scale_xyz)\u001b[0m\n\u001b[1;32m     79\u001b[0m sample_motion_outs \u001b[39m=\u001b[39m []\n\u001b[1;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m pts \u001b[39min\u001b[39;00m rays:\n\u001b[0;32m---> 81\u001b[0m   mv_output \u001b[39m=\u001b[39m _sample_motion_fields_forward_warp(\n\u001b[1;32m     82\u001b[0m                     pts\u001b[39m=\u001b[39;49mpts,\n\u001b[1;32m     83\u001b[0m                     motion_scale_Rs\u001b[39m=\u001b[39;49mmotion_scale_Rs[\u001b[39m0\u001b[39;49m], \n\u001b[1;32m     84\u001b[0m                     motion_Ts\u001b[39m=\u001b[39;49mmotion_Ts[\u001b[39m0\u001b[39;49m], \n\u001b[1;32m     85\u001b[0m                     motion_weights_vol\u001b[39m=\u001b[39;49mmotion_weights_vol,\n\u001b[1;32m     86\u001b[0m                     cnl_bbox_min_xyz\u001b[39m=\u001b[39;49mcnl_bbox_min_xyz, \n\u001b[1;32m     87\u001b[0m                     cnl_bbox_scale_xyz\u001b[39m=\u001b[39;49mcnl_bbox_scale_xyz,\n\u001b[1;32m     88\u001b[0m                     output_list\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mx_skel\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfg_likelihood_mask\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     89\u001b[0m   pts_mask \u001b[39m=\u001b[39m mv_output[\u001b[39m'\u001b[39m\u001b[39mfg_likelihood_mask\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     90\u001b[0m   cnl_pts \u001b[39m=\u001b[39m mv_output[\u001b[39m'\u001b[39m\u001b[39mx_skel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m, in \u001b[0;36m_sample_motion_fields_forward_warp\u001b[0;34m(pts, motion_scale_Rs, motion_Ts, motion_weights_vol, cnl_bbox_min_xyz, cnl_bbox_scale_xyz, output_list)\u001b[0m\n\u001b[1;32m     19\u001b[0m pos \u001b[39m=\u001b[39m (pos \u001b[39m-\u001b[39m cnl_bbox_min_xyz[\u001b[39mNone\u001b[39;00m, :]) \\\n\u001b[1;32m     20\u001b[0m     \u001b[39m*\u001b[39m cnl_bbox_scale_xyz[\u001b[39mNone\u001b[39;00m, :] \u001b[39m-\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[39m# Use JAX's map_coordinates to replace torch's grid_sample\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m weights \u001b[39m=\u001b[39m map_coordinates(motion_weights[jnp\u001b[39m.\u001b[39;49mnewaxis, i:i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, :, :, :], \n\u001b[1;32m     24\u001b[0m                           pos[jnp\u001b[39m.\u001b[39;49mnewaxis, jnp\u001b[39m.\u001b[39;49mnewaxis, jnp\u001b[39m.\u001b[39;49mnewaxis, :, :], \n\u001b[1;32m     25\u001b[0m                           order\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     26\u001b[0m weights \u001b[39m=\u001b[39m weights[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, :, jnp\u001b[39m.\u001b[39mnewaxis]  \u001b[39m# (4194304, 1)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m weights_list\u001b[39m.\u001b[39mappend(weights)\n",
      "File \u001b[0;32m/data/xymeng/anaconda3/envs/ham/lib/python3.9/site-packages/jax/_src/scipy/ndimage.py:141\u001b[0m, in \u001b[0;36mmap_coordinates\u001b[0;34m(input, coordinates, order, mode, cval)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m@_wraps\u001b[39m(scipy\u001b[39m.\u001b[39mndimage\u001b[39m.\u001b[39mmap_coordinates, lax_description\u001b[39m=\u001b[39mtextwrap\u001b[39m.\u001b[39mdedent(\u001b[39m\"\"\"\u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Only nearest neighbor (``order=0``), linear interpolation (``order=1``) and\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[39m    modes ``\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m\u001b[39m``, ``\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m'\u001b[39m\u001b[39m``, ``\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwrap\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`` ``\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmirror\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`` and ``\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreflect\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`` are currently supported.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[39minput\u001b[39m: ArrayLike, coordinates: Sequence[ArrayLike], order: \u001b[39mint\u001b[39m, mode: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m, cval: ArrayLike \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m,\n\u001b[1;32m    140\u001b[0m ):\n\u001b[0;32m--> 141\u001b[0m   \u001b[39mreturn\u001b[39;00m _map_coordinates(\u001b[39minput\u001b[39;49m, coordinates, order, mode, cval)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m/data/xymeng/anaconda3/envs/ham/lib/python3.9/site-packages/jax/_src/scipy/ndimage.py:82\u001b[0m, in \u001b[0;36m_map_coordinates\u001b[0;34m(input, coordinates, order, mode, cval)\u001b[0m\n\u001b[1;32m     79\u001b[0m cval \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39masarray(cval, input_arr\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(coordinates) \u001b[39m!=\u001b[39m input_arr\u001b[39m.\u001b[39mndim:\n\u001b[0;32m---> 82\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcoordinates must be a sequence of length input.ndim, but \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     83\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(coordinates), input_arr\u001b[39m.\u001b[39mndim))\n\u001b[1;32m     85\u001b[0m index_fixer \u001b[39m=\u001b[39m _INDEX_FIXERS\u001b[39m.\u001b[39mget(mode)\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m index_fixer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: coordinates must be a sequence of length input.ndim, but 1 != 5"
     ]
    }
   ],
   "source": [
    "from jax.scipy.ndimage import map_coordinates\n",
    "warped_rays = sample_motion_fields_forward_warp_mobile_nerf(\n",
    "    rays=rays,\n",
    "    motion_scale_Rs=motion_scale_Rs,\n",
    "    motion_Ts=motion_Ts,\n",
    "    motion_weights_vol=motion_weights_vol,\n",
    "    cnl_bbox_min_xyz=cnl_bbox_min_xyz,\n",
    "    cnl_bbox_scale_xyz=cnl_bbox_scale_xyz,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated Values (JAX): [ 2.5  7.5 12.5]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jscipy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Toy input image\n",
    "image = jnp.arange(16).reshape((4, 4)).astype(jnp.float32)\n",
    "\n",
    "# Define the sampling coordinates\n",
    "coords = jnp.array([[0.5, 0.5], [1.5, 1.5], [2.5, 2.5]]).reshape((3, 2))\n",
    "\n",
    "# JAX: Using map_coordinates\n",
    "interpolated_jax = jscipy.ndimage.map_coordinates(image, coords.T, order=1)\n",
    "\n",
    "# Convert JAX array to NumPy array\n",
    "image_np = jnp.asarray(image)\n",
    "image_np = np.array(image_np)\n",
    "\n",
    "# Convert coordinates to NumPy array and then PyTorch tensor\n",
    "coords_np = np.array(coords)\n",
    "grid = (coords_np / (np.array(image.shape[::-1]) - 1) * 2 - 1).reshape((1, 3, 2))\n",
    "grid_torch = torch.from_numpy(grid).float()\n",
    "\n",
    "# PyTorch: Using grid_sample\n",
    "image_torch = torch.from_numpy(image_np)\n",
    "# interpolated_torch = F.grid_sample(image_torch.unsqueeze(0).unsqueeze(0), grid_torch, align_corners=True).squeeze()\n",
    "\n",
    "print(\"Interpolated Values (JAX):\", interpolated_jax)\n",
    "# print(\"Interpolated Values (PyTorch):\", interpolated_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 4, 1, 1) 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "coordinates must be a sequence of length input.ndim, but 1 != 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(coords3\u001b[39m.\u001b[39mshape, \u001b[39mlen\u001b[39m(coords3))\n\u001b[1;32m     11\u001b[0m \u001b[39m# JAX: Using map_coordinates\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m interpolated_jax \u001b[39m=\u001b[39m jscipy\u001b[39m.\u001b[39;49mndimage\u001b[39m.\u001b[39;49mmap_coordinates(image, coords3\u001b[39m.\u001b[39;49mT, order\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m/data/xymeng/anaconda3/envs/ham/lib/python3.9/site-packages/jax/_src/scipy/ndimage.py:141\u001b[0m, in \u001b[0;36mmap_coordinates\u001b[0;34m(input, coordinates, order, mode, cval)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m@_wraps\u001b[39m(scipy\u001b[39m.\u001b[39mndimage\u001b[39m.\u001b[39mmap_coordinates, lax_description\u001b[39m=\u001b[39mtextwrap\u001b[39m.\u001b[39mdedent(\u001b[39m\"\"\"\u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Only nearest neighbor (``order=0``), linear interpolation (``order=1``) and\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[39m    modes ``\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m\u001b[39m``, ``\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m'\u001b[39m\u001b[39m``, ``\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwrap\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`` ``\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmirror\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`` and ``\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreflect\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`` are currently supported.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[39minput\u001b[39m: ArrayLike, coordinates: Sequence[ArrayLike], order: \u001b[39mint\u001b[39m, mode: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m, cval: ArrayLike \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m,\n\u001b[1;32m    140\u001b[0m ):\n\u001b[0;32m--> 141\u001b[0m   \u001b[39mreturn\u001b[39;00m _map_coordinates(\u001b[39minput\u001b[39;49m, coordinates, order, mode, cval)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m/data/xymeng/anaconda3/envs/ham/lib/python3.9/site-packages/jax/_src/scipy/ndimage.py:82\u001b[0m, in \u001b[0;36m_map_coordinates\u001b[0;34m(input, coordinates, order, mode, cval)\u001b[0m\n\u001b[1;32m     79\u001b[0m cval \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39masarray(cval, input_arr\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(coordinates) \u001b[39m!=\u001b[39m input_arr\u001b[39m.\u001b[39mndim:\n\u001b[0;32m---> 82\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcoordinates must be a sequence of length input.ndim, but \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     83\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(coordinates), input_arr\u001b[39m.\u001b[39mndim))\n\u001b[1;32m     85\u001b[0m index_fixer \u001b[39m=\u001b[39m _INDEX_FIXERS\u001b[39m.\u001b[39mget(mode)\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m index_fixer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: coordinates must be a sequence of length input.ndim, but 1 != 5"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jscipy\n",
    "\n",
    "# Toy input image\n",
    "image = jnp.arange(32*32*32).reshape((1, 1, 32, 32, 32)).astype(jnp.float32)\n",
    "\n",
    "# Define correct number of dimensions in the sampling coordinates\n",
    "coords3 = jnp.array([[0.5, 0.5], [0.5, 0.5]])[jnp.newaxis, jnp.newaxis, :, :].reshape(1,1,1,1,1)  # Three-dimensional coordinates\n",
    "print(coords3.shape, len(coords3))\n",
    "# JAX: Using map_coordinates\n",
    "interpolated_jax = jscipy.ndimage.map_coordinates(image, coords3.T, order=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobilehuman2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "812f86583856573ab981e32e0a4ea253908313fe37e9e80b0fe78dee9f3a443d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
